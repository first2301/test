{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA A100-SXM4-80GB\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print((torch.cuda._get_nvml_device_index(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델 초기화\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"../ai_models/base_models/BGE-m3-ko\",\n",
    "    model_kwargs={'device': 'cuda:0'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_pdf_directory(directory_path):\n",
    "#     loader = PyPDFDirectoryLoader(directory_path)\n",
    "#     pages = loader.load()\n",
    "#     return pages\n",
    "\n",
    "def load_pdf_directory(directory_path):\n",
    "    loader = PyPDFDirectoryLoader(directory_path)\n",
    "    pages = loader.load()\n",
    "\n",
    "    # 줄바꿈 노이즈 정리\n",
    "    for page in pages:\n",
    "        # 하이픈으로 줄바꿈된 단어 복원\n",
    "        page.page_content = page.page_content.replace(\"-\\n\", \"\")\n",
    "        # 일반 줄바꿈은 공백으로 변환\n",
    "        page.page_content = page.page_content.replace(\"\\n\", \" \")\n",
    "\n",
    "    return pages\n",
    "\n",
    "pdf_paths = \"../data/pdf\"\n",
    "pdf_data = load_pdf_directory(pdf_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=400,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len,\n",
    "        separators=[r\"\\n{2,}\", r\"\\n\", r\"[.!?]\", r\"[,;:]\", r\" \"],\n",
    "        is_separator_regex=True\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "chunks = split_documents(pdf_data)\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=400,  # 한 청크에 너무 많은 문장이 담기지 않도록\n",
    "#     chunk_overlap=50,  # 앞뒤 문맥 연결 위해 소폭 겹침\n",
    "#     separators=[r\"\\n{2,}\", r\"\\n\", r\"[.!?]\", r\"[,;:]\", r\" \"],  # 문단, 줄, 문장, 쉼표, 공백 순으로 분할\n",
    "#     is_separator_regex=True\n",
    "# )\n",
    "\n",
    "# chunks = text_splitter.split_documents(pdf_data)\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=500,  # PDF 문서는 더 작은 청크로 나누는 것이 좋음\n",
    "#     chunk_overlap=50, # 청크 간 중복도 줄임\n",
    "#     length_function=len,\n",
    "#     separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \";\", \":\", \" \", \"\"],  # PDF 문서의 구조를 고려한 구분자 추가\n",
    "#     is_separator_regex=False\n",
    "# )\n",
    "\n",
    "# chunks = text_splitter.split_documents(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 벡터 스토어 생성\n",
    "db = FAISS.from_documents(\n",
    "    chunks, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 벡터 스토어 저장\n",
    "faiss_index_directory = \"./faiss_index_directory\"\n",
    "os.makedirs(faiss_index_directory, exist_ok=True)\n",
    "db.save_local(faiss_index_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## 검색결과 1\n",
      "내용: ., 2021)의 연구에서 피지컬 AI는 디지털 AI의 확장 개념으로, “물리적 세계에서 자율적으로 작동하는 지능형 시스템”으로 정의∙ 저자들은 본 논문을 통해 피지컬  AI는 단순한  로봇  기술 을 넘 어, 센서·액추에 이터·AI 알고 리즘이  통합 된 시 스템으 로서 현실 환경에서의 상호작용성과 적응성을 핵심으로 하며, 차세대 인공지능의 핵심 패러다임이 될 수 있다고 강조●피지컬 AI 개념은 학계에서 기존의 체화된 AI(Embodied AI), 소프트 로보틱스(Soft Robotics), 사이버물리시스템(Cyber-Physical System, CPS), 적응형 AI(Adaptive AI) 등의 개념들과 밀접하게 연결∙ 이 중, 피지컬 AI와 가장 근접한 개념은 ‘체화된 AI’로\n",
      "출처: {'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-05-13T13:38:44+09:00', 'author': 'Kevin', 'moddate': '2025-05-13T13:38:44+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/IS-202 피지컬 AI의 현황과 시사점.pdf', 'total_pages': 48, 'page': 7, 'page_label': '8'}\n",
      "\n",
      "## 검색결과 2\n",
      "내용: SPRi\u0000이슈리포트\u0000IS-202 피지컬\u0000AI의\u0000현황과\u0000시사점 5 (embodied reasoning)’ 능력을 부여하며, 이는 피지컬 AI가 현실 세계에서 자율성과 적응성을 갖춘 행동 실행 주체로 진화하는 방향성을 제시●미국의 AI 전문 인증기관 USAII(United States Artificial Intelligence Institute)*은 피지컬 AI를 “AI가 데이터 처리를 넘어 실제 세계에서 물리적 상호작용을 지능적으로 수행하는 기술”로 정의(USAII, 2025)* USAII는 글로벌 AI 전문가 양성을 목표로 다양한 산업 맞춤형 인증을 제공하며\n",
      "출처: {'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-05-13T13:38:44+09:00', 'author': 'Kevin', 'moddate': '2025-05-13T13:38:44+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/IS-202 피지컬 AI의 현황과 시사점.pdf', 'total_pages': 48, 'page': 9, 'page_label': '10'}\n",
      "\n",
      "## 검색결과 3\n",
      "내용: , 피지컬 AI와 가장 근접한 개념은 ‘체화된 AI’로, 이는 AI가 물리적 또는 가상 환경 속에서 몸체(body)를 갖고 인지하고 행동하는 형태의 AI로 로봇공학과 인지과학에서 오랫동안 논의되어 온 개념(Liu, et al\n",
      "출처: {'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-05-13T13:38:44+09:00', 'author': 'Kevin', 'moddate': '2025-05-13T13:38:44+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/IS-202 피지컬 AI의 현황과 시사점.pdf', 'total_pages': 48, 'page': 7, 'page_label': '8'}\n"
     ]
    }
   ],
   "source": [
    "# FAISS 벡터 스토어에서 유사도 검색\n",
    "query = \"피지컬 AI 란?\"\n",
    "docs = db.similarity_search(query, k=3)  # k는 반환할 문서 수\n",
    "\n",
    "# 검색 결과 출력\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n## 검색결과 {i+1}\")\n",
    "    print(f\"내용: {doc.page_content}\")\n",
    "    print(f\"출처: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open faiss_index_directory/index.faiss for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_1002358/4284309924.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m faiss_index_directory = \u001b[33m\"./faiss_index_directory\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vectorstore = FAISS.load_local(faiss_index_directory, embeddings, allow_dangerous_deserialization=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m retriever = vectorstore.as_retriever(    \n\u001b[32m      4\u001b[39m     search_type=\u001b[33m\"similarity_score_threshold\"\u001b[39m,\n\u001b[32m      5\u001b[39m     search_kwargs={\u001b[33m\"score_threshold\"\u001b[39m: \u001b[32m0.5\u001b[39m, \u001b[33m\"k\"\u001b[39m: \u001b[32m3\u001b[39m}\n",
      "\u001b[32m~/chatbot/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/faiss.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[39m\n\u001b[32m   1201\u001b[39m             )\n\u001b[32m   1202\u001b[39m         path = Path(folder_path)\n\u001b[32m   1203\u001b[39m         \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n\u001b[32m   1204\u001b[39m         faiss = dependable_faiss_import()\n\u001b[32m-> \u001b[39m\u001b[32m1205\u001b[39m         index = faiss.read_index(str(path / \u001b[33mf\"{index_name}.faiss\"\u001b[39m))\n\u001b[32m   1206\u001b[39m \n\u001b[32m   1207\u001b[39m         \u001b[38;5;66;03m# load docstore and index_to_docstore_id\u001b[39;00m\n\u001b[32m   1208\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m open(path / \u001b[33mf\"{index_name}.pkl\"\u001b[39m, \u001b[33m\"rb\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32m~/chatbot/.venv/lib/python3.11/site-packages/faiss/swigfaiss_avx2.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m  10946\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m read_index(*args):\n\u001b[32m> \u001b[39m\u001b[32m10947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _swigfaiss_avx2.read_index(*args)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open faiss_index_directory/index.faiss for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "faiss_index_directory = \"./faiss_index_directory\"\n",
    "vectorstore = FAISS.load_local(faiss_index_directory, embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(    \n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"score_threshold\": 0.5, \"k\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='019c7d8e-5cce-4268-b0f2-09166c4e9ffa', metadata={'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-04-28T10:13:10+09:00', 'author': 'Sohyeon', 'moddate': '2025-04-28T10:13:10+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/RE-189. 2024년 국내외 인공지능 산업 동향 연구.pdf', 'total_pages': 367, 'page': 357, 'page_label': '358'}, page_content='<표> 국내 AI 기업 동향'),\n",
       " Document(id='30d6ec03-d47c-49c1-aa59-e631c9a24ec2', metadata={'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-04-28T10:13:10+09:00', 'author': 'Sohyeon', 'moddate': '2025-04-28T10:13:10+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/RE-189. 2024년 국내외 인공지능 산업 동향 연구.pdf', 'total_pages': 367, 'page': 359, 'page_label': '360'}, page_content='<표> 해외 AI 기업 동향'),\n",
       " Document(id='aee8e9e9-8c55-497b-af8f-25ef04bc223a', metadata={'producer': 'Hancom PDF 1.3.0.550', 'creator': 'Hwp 2018 10.0.0.14515', 'creationdate': '2025-04-28T10:13:10+09:00', 'author': 'Sohyeon', 'moddate': '2025-04-28T10:13:10+09:00', 'pdfversion': '1.4', 'source': '../data/pdf/RE-189. 2024년 국내외 인공지능 산업 동향 연구.pdf', 'total_pages': 367, 'page': 7, 'page_label': '8'}, page_content='.AI의 한국과 미국의 주요 트렌드 비교· · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·158')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search(k=3, query=\"ai 동향\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

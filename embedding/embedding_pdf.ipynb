{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
    "\n",
    "from elasticsearch import helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load single PDF file\n",
    "def load_single_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load()\n",
    "    return pages\n",
    "\n",
    "# Load multiple PDF files from directory\n",
    "def load_pdf_directory(directory_path):\n",
    "    loader = PyPDFDirectoryLoader(directory_path)\n",
    "    pages = loader.load()\n",
    "    return pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_paths = \"../data/pdf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_data = load_pdf_directory(pdf_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # PDF 문서는 더 작은 청크로 나누는 것이 좋음\n",
    "    chunk_overlap=50, # 청크 간 중복도 줄임\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \";\", \":\", \" \", \"\"],  # PDF 문서의 구조를 고려한 구분자 추가\n",
    "    is_separator_regex=False\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"../ai_models/base_models/BGE-m3-ko\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "es = Elasticsearch(\"http://127.0.0.1:9200\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'error': {'root_cause': [{'type': 'resource_already_exists_exception', 'reason': 'index [pdf/nNfCzCNMQrW82xV-II5ouw] already exists', 'index_uuid': 'nNfCzCNMQrW82xV-II5ouw', 'index': 'pdf'}], 'type': 'resource_already_exists_exception', 'reason': 'index [pdf/nNfCzCNMQrW82xV-II5ouw] already exists', 'index_uuid': 'nNfCzCNMQrW82xV-II5ouw', 'index': 'pdf'}, 'status': 400})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.options(ignore_status=400).indices.create(\n",
    "    index=\"pdf\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 1024,  # 모델에 따라 조정\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13590/13590 [2:28:05<00:00,  1.53it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13590, [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = []\n",
    "for chunk in tqdm(chunks):\n",
    "    text = chunk.page_content\n",
    "    vector = embeddings.embed_documents([text])[0]  # ✅ 문서용\n",
    "\n",
    "    actions.append({\n",
    "        \"_index\": \"pdf\",\n",
    "        \"_source\": {\n",
    "            \"content\": text,\n",
    "            \"embedding\": vector\n",
    "        }\n",
    "    })\n",
    "\n",
    "helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: 0.8313\n",
      "문서 내용: <표 2-1> 피지컬 AI 정의 요약\n",
      "* 출처: 소프트웨어정책연구소 정리(2025.04.01.)■현재까지 피지컬 AI에 대한 통일된 정의는 부재한 상황이나, 산·학·연 각 분야에서는 공통적으로 ‘AI의 물리적 구현’, ‘물리적 인터페이스를 통한 실제 세계와의 상호작용’, ‘자율적 판단·행동’ 등을 핵심 요소로 강조●본 보고서에서는 이러한 핵심 요소를 바탕으로 피지컬 AI를 아래와 같이 정의하고  주요 기술과 유형을 분석AI가 물리적 실체 안에 구현되어 센서와 액추에이터 등을 통해 현실 세계를 인식하고, 자율적으로 판단·행동함으로써 환경과 유기적으로 상호작용할 수 있는 시스템피지컬 AI 정의\n",
      "\n",
      "점수: 0.8273\n",
      "문서 내용: <표 2-2> 피지컬 AI 유형 구분\n",
      "* 출처: 소프트웨어정책연구소 정리(2025.04.01.)\n",
      "\n",
      "점수: 0.8255\n",
      "문서 내용: 피지컬 AI를 정의하고, 그 실현을 위한 관련 기술 개발에 박차●NVIDIA는 피지컬 AI를 “현실(물리적) 세계에서 복잡한 행동을 인식, 이해 및 수행할 수 있는 자율 시스템(로봇, 자율주행차, 스마트 공간 등)”으로 설명(NVIDIA, 2025e)s∙ 피지컬 AI는 물리 세계에 대한 통찰을 생성하고 실행할 수 있다는 점에서 ‘생성 피지컬 AI(Generative Physical AI)’로도 불리며, 이는 기존 생성 AI를 확장해 3D 세계의 공간적 관계와 물리적 행동을 학습하고, 단순한 시각 재현을 넘어 현실의 물리 법칙을 반영하는 시스템∙ 과 거  자 율  기 계 가  주 변  환 경  인 지 와  상 호 작 용 에  한 계 가  있 었 던  반 면, 피 지 컬  AI는  현 실  세 계 와 의  자 연 스 러 운  상 호 작 용 을 가능하게 함으로써, 복잡한 작업 수행 능력을 높이고 인간과의 협업을 더욱 효율적이고 직관적으로 만드는 데 기여●구글의\n",
      "\n",
      "점수: 0.8218\n",
      "문서 내용: . et al., 2021)의 연구에서 피지컬 AI는 디지털 AI의 확장 개념으로, “물리적 세계에서 자율적으로 작동하는 지능형 시스템”으로 정의∙ 저자들은 본 논문을 통해 피지컬  AI는 단순한  로봇  기술 을 넘 어, 센서·액추에 이터·AI 알고 리즘이  통합 된 시 스템으 로서 현실 환경에서의 상호작용성과 적응성을 핵심으로 하며, 차세대 인공지능의 핵심 패러다임이 될 수 있다고 강조●피지컬 AI 개념은 학계에서 기존의 체화된 AI(Embodied AI), 소프트 로보틱스(Soft Robotics), 사이버물리시스템(Cyber-Physical System, CPS), 적응형 AI(Adaptive AI) 등의 개념들과 밀접하게 연결∙ 이 중, 피지컬 AI와 가장 근접한 개념은 ‘체화된 AI’로, 이는 AI가 물리적 또는 가상 환경 속에서 몸체(body)를 갖고 인지하고 행동하는 형태의 AI로 로봇공학과 인지과학에서 오랫동안 논의되어 온 개념(Liu, et al\n",
      "\n",
      "점수: 0.8207\n",
      "문서 내용: .2\u0000피지컬\u0000AI의\u0000주요\u0000기술■피지컬 AI는 기반모델(Foundation Model), 컴퓨터 비전(Computer Vision), 엣지 컴퓨팅(Edge Computing), 자율 제어 기술 등 첨단기술의 융합을 통해 물리적 세계에서 인간처럼 감지하고, 해석하며, 자율적으로 행동하는 지능형 물리 시스템으로 진화●피지컬 AI는 기본적으로 AI 알고리즘(두뇌), 센서 및 컴퓨터 비전(감각), 엣지 컴퓨팅·네트워크 인프라(연결), 제어 및 액추에이터(행동)라는 네 가지 축을 기반으로 구성●주요 기술들은 피지컬 AI를 구성하는 개별 핵심 요소로서 독립적으로도 중요한 역할을 수행하지만, 동시에 상호 유기적으로 결합되어 결과적으로 피지컬 AI의 통합적 구현과 실현을 가능하게 함■(AI 알고리즘) 광범위한 데이터로부터 학습하고, 다양한 상황을 인식하여 자율적으로 판단·계획·추론하는 등 피지컬 AI의 지능적 의사결정을 담당하는 핵심 기술●초기의 고정된 작업 수행 중심에서 벗어나, 피지컬 AI가\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"피지컬컬 AI 설명\"\n",
    "query_vector = embeddings.embed_query(query)\n",
    "\n",
    "response = es.search(\n",
    "    index=\"pdf\",\n",
    "    knn={\n",
    "        \"field\": \"embedding\",\n",
    "        \"query_vector\": query_vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 20\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f\"점수: {hit['_score']:.4f}\")\n",
    "    print(f\"문서 내용: {hit['_source']['content']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

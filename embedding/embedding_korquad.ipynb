{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset: https://korquad.github.io/category/1.0_KOR.html\n",
    "- elasticsearch: https://www.elastic.co/docs/deploy-manage/deploy/self-managed/install-elasticsearch-docker-basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -d --name es01 \\\n",
    "#   --net elastic \\\n",
    "#   -p 9200:9200 -m 1GB \\\n",
    "#   -e \"discovery.type=single-node\" \\\n",
    "#   -e \"xpack.security.enabled=false\" \\\n",
    "#   -e \"xpack.security.http.ssl.enabled=false\" \\\n",
    "#   docker.elastic.co/elasticsearch/elasticsearch:9.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset('json', data_files='..\\\\data\\\\korquad\\\\KorQuAD_v1.0_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "korquad_data = ds['train'][0]['data']  # ✔️ 이게 실제 문서 리스트\n",
    "\n",
    "for item in korquad_data:\n",
    "    for para in item['paragraphs']:\n",
    "        context = para['context']\n",
    "        documents.append(Document(page_content=context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"../ai_models/base_models/BGE-m3-ko\",\n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "es = Elasticsearch(\"http://127.0.0.1:9200\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'korquad'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.options(ignore_status=400).indices.create(\n",
    "    index=\"korquad\",\n",
    "    mappings={\n",
    "        \"properties\": {\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 1024,  # 모델에 따라 조정\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13981/13981 [2:49:04<00:00,  1.38it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13981, [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "actions = []\n",
    "for chunk in tqdm(chunks):\n",
    "    text = chunk.page_content\n",
    "    vector = embeddings.embed_documents([text])[0]  # ✅ 문서용\n",
    "\n",
    "    actions.append({\n",
    "        \"_index\": \"korquad\",\n",
    "        \"_source\": {\n",
    "            \"content\": text,\n",
    "            \"embedding\": vector\n",
    "        }\n",
    "    })\n",
    "\n",
    "helpers.bulk(es, actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "점수: 0.6783\n",
      "문서 내용: GPU는 펌웨어 이미지를 통해 접근이 가능하며, 이 이미지는 SD 카드로부터 부팅할때 GPU에 로드된다. 이 펌웨어 이미지는 바이너리 블롭으로도 알려져 있는데, 리눅스용 드라이버는 공개되지 않은 사유 소프트웨어이다. 응용 소프트웨어를 사용하게 되면, 비공개 실시간 라이브러리를 호출하게되고, 이는 다시 리눅스 내의 오픈 소스 드라이버를 호출하게 된다. 제공되는 커널 드라이버의 API가 이런 비공개 라이브러리를 지원하기 위해 특화되어 있다. 비디오 응용 프로그램은 OpenMAX를 사용하며, 3D 그래픽은 OpenGL ES를 사용하고, 2D 응용 프로그램은 OpenVG를 사용한다. OpenVG는 다시 EGL을 사용하게 된다. OpenMAX와 EGL은 다시 커널의 오픈소스 커널 드라이버를 사용하게된다.\n",
      "\n",
      "점수: 0.6781\n",
      "문서 내용: 이에 대해 김경수는 사실이 알려진 2018년 4월 14일 오후 9시 30분 국회 정론관에서 기자회견을 하면서 자신에 관한 보도를 해명했다. 김경수는 총선이 열린 2016년부터 인터넷 댓글 조작범 김동원(필명: 드루킹)을 만나 범인이 운영하는 파주의 느릅나무 출판사 사무실을 방문하였다고 주장했다. 김경수는 댓글조작 사건의 범인 김동원(드루킹)에게서 일본 오사카 총영사를 청탁받아 청와대에 추천한 것은 사실이지만, 청와대에서 어렵다는 연락을 받아 이를 전해줬다고 해명했다. 청와대는 \"댓글을 조작한 김동원(드루킹)이 주(駐)오사카 총영사로 김경수 의원에게 추천한 인사를 2018년 2월에 청와대 연풍문 2층에서 1시간가량 직접 만났으나 적합하지 않다고 판단했다.\"고 해명했다.\n",
      "\n",
      "점수: 0.6745\n",
      "문서 내용: 박동열 대전지방국세청장에게 정보담당 경찰관, 개인사업자 등 6명이 '증권가 지라시'와 풍문을 전달하였고, 조응천 대통령비서실 공직기강비서관은 박관천 공직기강비서관실 행정관에게 동향파악을 지시하였다. 이에 박관천은 박동열에게 관련 사실을 확인하였고, 박관천은 박동열로부터 전달받은 풍문과 정보를 과장하고 추가하여 정윤회의 언동인 것처럼 작성한 뒤 조응천에게 보고하였다. 검찰 조사에서 조응천은 2014년 말 무렵 대통령비서실장 또는 대통비서실 민정수석비서관으로부터 대통령비서실장 사퇴설의 경위를 파악해보라는 지시를 받은 것으로 기억한다고 주장했으나, 김기춘 대통령비서실장은 어느 누구에게도 이 같은 지시를 한 사실이 없다고 고소 대리인을 통해 진술하였으며, 홍경식 전 민정수석비서관 역시 비서실장으로부터 이런 지시를 받거나 자신이 조응천에게 지시한 사실이 없다고 진술하였다.\n",
      "\n",
      "점수: 0.6730\n",
      "문서 내용: .\n",
      "\n",
      "점수: 0.6730\n",
      "문서 내용: .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"gdpr 대해 알려줘\"\n",
    "query_vector = embeddings.embed_query(query)\n",
    "\n",
    "response = es.search(\n",
    "    index=\"korquad\",\n",
    "    knn={\n",
    "        \"field\": \"embedding\",\n",
    "        \"query_vector\": query_vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(f\"점수: {hit['_score']:.4f}\")\n",
    "    print(f\"문서 내용: {hit['_source']['content']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

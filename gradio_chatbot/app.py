from llama_cpp import Llama
import gradio as gr

# ëª¨ë¸ ë¡œë”©
llm = Llama(
    model_path="../ai_models/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M.gguf",
    n_ctx=2048,
    n_threads=8,
    n_batch=64
)

def chat_with_bot(message, history):
    # ì•„ì´ì½˜ ë° ì´ë¦„ ë¼ë²¨
    user_icon = "ğŸ™‹â€â™‚ï¸"
    ai_icon = "ğŸ¤–"

    system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
    chat_history = ""
    for human, ai in history:
        chat_history += f"ì‚¬ìš©ì: {human}\nAI: {ai}\n"
    prompt = f"{system_prompt}{chat_history}ì‚¬ìš©ì: {message}\nAI:"

    output = llm(
        prompt,
        max_tokens=512,
        stop=["ì‚¬ìš©ì:", "AI:"],
        echo=False,
        temperature=0.7,
        top_p=0.9
    )

    bot_response = output["choices"][0]["text"].strip()

    # ë©”ì‹œì§€ HTML í¬ë§·
    user_msg = f"{user_icon} <b>ì‚¬ìš©ì:</b><br>{message}"
    formatted_response = f"{ai_icon} <b>AI:</b><br>â€¢ " + "<br>â€¢ ".join(bot_response.split("\n"))
    
    history.append((user_msg, formatted_response))
    return "", history, history

# Gradio UI êµ¬ì„±
with gr.Blocks() as demo:
    gr.Markdown("## ğŸŒ¸ <b>LLaMA-3.2 Korean Bllossom 3B Chatbot</b>")
    
    chatbot = gr.Chatbot(show_label=False, bubble_full_width=False)
    msg = gr.Textbox(placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label="ì…ë ¥")
    clear = gr.Button("ì´ˆê¸°í™”")

    state = gr.State([])

    msg.submit(chat_with_bot, [msg, state], [msg, chatbot, state])
    clear.click(lambda: ([], []), None, [chatbot, state])

demo.launch(share=True)  # í•„ìš”ì‹œ share=True

# from llama_cpp import Llama
# import gradio as gr

# # ëª¨ë¸ ë¡œë”©
# llm = Llama(
#     model_path="../ai_models/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M.gguf",
#     n_ctx=2048,
#     n_threads=8,   # ì‚¬ìš© í™˜ê²½ì— ë§ê²Œ ì¡°ì ˆ
#     n_batch=64
# )

# # ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜
# def chat_with_bot(message, history):
#     system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
#     chat_history = ""
#     for human, ai in history:
#         chat_history += f"ì‚¬ìš©ì: {human}\nAI: {ai}\n"
#     prompt = f"{system_prompt}{chat_history}ì‚¬ìš©ì: {message}\nAI:"

#     output = llm(
#         prompt,
#         max_tokens=512,
#         stop=["ì‚¬ìš©ì:", "AI:"],
#         echo=False,
#         temperature=0.7,
#         top_p=0.9
#     )

#     bot_response = output["choices"][0]["text"].strip()
#     history.append((message, bot_response))
    
#     # âœ… ë°˜ë“œì‹œ 3ê°œë¥¼ ë°˜í™˜í•´ì•¼ í•¨ (Textbox, Chatbot, State)
#     return "", history, history


# # Gradio UI êµ¬ì„±
# with gr.Blocks() as demo:
#     gr.Markdown("## ğŸŒ¸ LLaMA-3.2 Korean Bllossom 3B Chatbot")
    
#     chatbot = gr.Chatbot()
#     msg = gr.Textbox(placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label="ì…ë ¥")
#     clear = gr.Button("ì´ˆê¸°í™”")

#     state = gr.State([])

#     msg.submit(chat_with_bot, [msg, state], [msg, chatbot, state])
#     clear.click(lambda: ([], []), None, [chatbot, state])

# demo.launch()

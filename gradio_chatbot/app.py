from llama_cpp import Llama
import gradio as gr

# ëª¨ë¸ ë¡œë”©
llm = Llama(
    model_path="../ai_models/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M/llama-3.2-Korean-Bllossom-3B-gguf-Q4_K_M.gguf",
    n_ctx=2048,
    n_threads=8,   # ì‚¬ìš© í™˜ê²½ì— ë§ê²Œ ì¡°ì ˆ
    n_batch=64
)

# ì±—ë´‡ ì‘ë‹µ í•¨ìˆ˜
def chat_with_bot(message, history):
    system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
    chat_history = ""
    for human, ai in history:
        chat_history += f"ì‚¬ìš©ì: {human}\nAI: {ai}\n"
    prompt = f"{system_prompt}{chat_history}ì‚¬ìš©ì: {message}\nAI:"

    output = llm(
        prompt,
        max_tokens=512,
        stop=["ì‚¬ìš©ì:", "AI:"],
        echo=False,
        temperature=0.7,
        top_p=0.9
    )

    bot_response = output["choices"][0]["text"].strip()
    history.append((message, bot_response))
    
    # âœ… ë°˜ë“œì‹œ 3ê°œë¥¼ ë°˜í™˜í•´ì•¼ í•¨ (Textbox, Chatbot, State)
    return "", history, history

# def chat_with_bot(message, history):
#     # historyë¥¼ ë¬¸ìì—´ë¡œ ì´ì–´ë¶™ì´ê¸°
#     system_prompt = "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì±—ë´‡ì…ë‹ˆë‹¤.\n"
#     chat_history = ""
#     for human, ai in history:
#         chat_history += f"ì‚¬ìš©ì: {human}\nAI: {ai}\n"
#     prompt = f"{system_prompt}{chat_history}ì‚¬ìš©ì: {message}\nAI:"

#     # Llama ëª¨ë¸ í˜¸ì¶œ
#     output = llm(
#         prompt,
#         max_tokens=512,
#         stop=["ì‚¬ìš©ì:", "AI:"],
#         echo=False,
#         temperature=0.7,
#         top_p=0.9
#     )

#     bot_response = output["choices"][0]["text"].strip()
#     history.append((message, bot_response))
#     return "", history

# Gradio UI êµ¬ì„±
with gr.Blocks() as demo:
    gr.Markdown("## ğŸŒ¸ LLaMA-3.2 Korean Bllossom 3B Chatbot")
    
    chatbot = gr.Chatbot()
    msg = gr.Textbox(placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...", label="ì…ë ¥")
    clear = gr.Button("ì´ˆê¸°í™”")

    state = gr.State([])

    msg.submit(chat_with_bot, [msg, state], [msg, chatbot, state])
    clear.click(lambda: ([], []), None, [chatbot, state])

demo.launch()
